{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T12:55:42.183170Z",
     "iopub.status.busy": "2024-12-28T12:55:42.182876Z",
     "iopub.status.idle": "2024-12-28T12:55:44.568164Z",
     "shell.execute_reply": "2024-12-28T12:55:44.567203Z",
     "shell.execute_reply.started": "2024-12-28T12:55:42.183139Z"
    },
    "id": "suG621BCcrxB",
    "outputId": "edfdcf1c-5e4a-4dec-b377-b4b532b79990",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CAST'...\n",
      "remote: Enumerating objects: 1289, done.\u001b[K\n",
      "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
      "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
      "remote: Total 1289 (delta 131), reused 300 (delta 125), pack-reused 976 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1289/1289), 41.99 MiB | 37.95 MiB/s, done.\n",
      "Resolving deltas: 100% (582/582), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/twke18/CAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1+cu116 --index-url https://download.pytorch.org/whl/cu116\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T12:55:44.570536Z",
     "iopub.status.busy": "2024-12-28T12:55:44.570203Z",
     "iopub.status.idle": "2024-12-28T12:58:02.342086Z",
     "shell.execute_reply": "2024-12-28T12:58:02.340992Z",
     "shell.execute_reply.started": "2024-12-28T12:55:44.570514Z"
    },
    "id": "hWIRpCBGctiH",
    "outputId": "ced077ce-2f0e-42e8-8efd-5a20cebac771",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchdata\n",
      "  Downloading torchdata-0.10.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.32.3)\n",
      "Collecting torch>=2 (from torchdata)\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=2->torchdata)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2->torchdata)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2->torchdata) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
      "Downloading torchdata-0.10.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchdata\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchdata-0.10.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dgl==1.1.3+cu121 -f https://data.dgl.ai/wheels/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T12:58:02.344024Z",
     "iopub.status.busy": "2024-12-28T12:58:02.343701Z",
     "iopub.status.idle": "2024-12-28T13:01:14.105789Z",
     "shell.execute_reply": "2024-12-28T13:01:14.104869Z",
     "shell.execute_reply.started": "2024-12-28T12:58:02.344002Z"
    },
    "id": "ZaVFLu3LcvJ3",
    "outputId": "d641934d-6345-4e3c-ee06-0080d120e71d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: 'python=3.9': Expected end or semicolon (after name and no valid version specifier)\n",
      "    python=3.9\n",
      "          ^\n",
      "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "\u001b[31mERROR: Invalid requirement: 'pytorch-cuda=11.6': Expected end or semicolon (after name and no valid version specifier)\n",
      "    pytorch-cuda=11.6\n",
      "                ^\n",
      "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.13.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch==1.13.1\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (4.12.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.32.3)\n",
      "Collecting torch==1.13.1 (from torchvision==0.14.1)\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (10.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchvision==0.14.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchvision==0.14.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchvision==0.14.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchvision==0.14.1) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (71.0.4)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2024.8.30)\n",
      "Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
      "torchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.13.1\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n",
      "Collecting timm==0.4.12\n",
      "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12) (71.0.4)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12) (0.44.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2024.8.30)\n",
      "Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 1.0.12\n",
      "    Uninstalling timm-1.0.12:\n",
      "      Successfully uninstalled timm-1.0.12\n",
      "Successfully installed timm-0.4.12\n",
      "Collecting setuptools==58.0.4\n",
      "  Downloading setuptools-58.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading setuptools-58.0.4-py3-none-any.whl (816 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.5/816.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 71.0.4\n",
      "    Uninstalling setuptools-71.0.4:\n",
      "      Successfully uninstalled setuptools-71.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "arviz 0.19.0 requires setuptools>=60.0.0, but you have setuptools 58.0.4 which is incompatible.\n",
      "pandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pytensor 2.25.4 requires setuptools>=59.0.0, but you have setuptools 58.0.4 which is incompatible.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
      "torchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-58.0.4\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (58.0.4)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Collecting hostlist\n",
      "  Downloading hostlist-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hostlist) (6.0.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from hostlist) (2.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hostlist) (2.32.3)\n",
      "Collecting cherrypy (from hostlist)\n",
      "  Downloading CherryPy-18.10.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (from hostlist) (3.1.43)\n",
      "Collecting ansible-cmdb (from hostlist)\n",
      "  Downloading ansible_cmdb-1.31-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting typing (from hostlist)\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from ansible-cmdb->hostlist) (1.3.8)\n",
      "Collecting ushlex (from ansible-cmdb->hostlist)\n",
      "  Downloading ushlex-0.99.1.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jsonxs (from ansible-cmdb->hostlist)\n",
      "  Downloading jsonxs-0.6.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting cheroot>=8.2.1 (from cherrypy->hostlist)\n",
      "  Downloading cheroot-10.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting portend>=2.1.1 (from cherrypy->hostlist)\n",
      "  Downloading portend-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->hostlist) (10.5.0)\n",
      "Collecting zc.lockfile (from cherrypy->hostlist)\n",
      "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting jaraco.collections (from cherrypy->hostlist)\n",
      "  Downloading jaraco.collections-5.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython->hostlist) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (2024.8.30)\n",
      "Collecting jaraco.functools (from cheroot>=8.2.1->cherrypy->hostlist)\n",
      "  Downloading jaraco.functools-4.1.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython->hostlist) (5.0.1)\n",
      "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->hostlist)\n",
      "  Downloading tempora-5.7.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting jaraco.text (from jaraco.collections->cherrypy->hostlist)\n",
      "  Downloading jaraco.text-4.0.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->ansible-cmdb->hostlist) (2.1.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->hostlist) (58.0.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->hostlist) (2.8.2)\n",
      "Collecting jaraco.context>=4.1 (from jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
      "  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting autocommand (from jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
      "  Downloading autocommand-2.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting backports.tarfile (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->tempora>=1.8->portend>=2.1.1->cherrypy->hostlist) (1.16.0)\n",
      "Downloading hostlist-1.4.8-py3-none-any.whl (34 kB)\n",
      "Downloading ansible_cmdb-1.31-py2.py3-none-any.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading CherryPy-18.10.0-py3-none-any.whl (349 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.8/349.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cheroot-10.0.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portend-3.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading jaraco.collections-5.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
      "Downloading tempora-5.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jaraco.functools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Downloading jaraco.text-4.0.0-py3-none-any.whl (11 kB)\n",
      "Downloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Building wheels for collected packages: typing, jsonxs, ushlex\n",
      "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26324 sha256=152d01ad51e10f190f6dd0340626b3552e4447c1613752e9a5da41e6f4b2c7ce\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
      "  Building wheel for jsonxs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for jsonxs: filename=jsonxs-0.6-py3-none-any.whl size=4676 sha256=4626ffebd4895fae2ac600684e256dc946af8513188a8903d7e660fdaf0c1453\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/81/b1/a3db92b8e5b7691128d659cbe4e12bffd54ece2748be6295a2\n",
      "  Building wheel for ushlex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ushlex: filename=ushlex-0.99.1-py3-none-any.whl size=4416 sha256=a8adde709ca5542893848cc1800b649624fee9813cf81559d0aafb91ac3ef0d5\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/e4/80/4de44668798392eb2f5b24f0130df2f5d28b43cb256bf9c1f9\n",
      "Successfully built typing jsonxs ushlex\n",
      "Installing collected packages: ushlex, jsonxs, zc.lockfile, typing, jaraco.functools, backports.tarfile, autocommand, tempora, jaraco.context, cheroot, ansible-cmdb, portend, jaraco.text, jaraco.collections, cherrypy, hostlist\n",
      "Successfully installed ansible-cmdb-1.31 autocommand-2.2.2 backports.tarfile-1.2.0 cheroot-10.0.1 cherrypy-18.10.0 hostlist-1.4.8 jaraco.collections-5.1.0 jaraco.context-6.0.1 jaraco.functools-4.1.0 jaraco.text-4.0.0 jsonxs-0.6 portend-3.2.0 tempora-5.7.0 typing-3.7.4.3 ushlex-0.99.1 zc.lockfile-3.0.post1\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
      "Collecting mmcv==1.3.8\n",
      "  Downloading mmcv-1.3.8.tar.gz (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting addict (from mmcv==1.3.8)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (10.4.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (6.0.2)\n",
      "Collecting yapf (from mmcv==1.3.8)\n",
      "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.3.8) (4.3.6)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.3.8) (2.0.1)\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mmcv: filename=mmcv-1.3.8-py2.py3-none-any.whl size=451083 sha256=5afb4ac8a1d6c96b10e724560a6dec103085dbafda770ec38d59e3fe7486afd8\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/6d/b8/f51fdd13994b141f943a88961c4a315f0b614b20ab1ba2e2c7\n",
      "Successfully built mmcv\n",
      "Installing collected packages: addict, yapf, mmcv\n",
      "Successfully installed addict-2.4.0 mmcv-1.3.8 yapf-0.43.0\n",
      "Collecting mmsegmentation==0.14.1\n",
      "  Downloading mmsegmentation-0.14.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (1.26.4)\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (3.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmsegmentation==0.14.1) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==0.14.1) (1.16.0)\n",
      "Downloading mmsegmentation-0.14.1-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mmsegmentation\n",
      "Successfully installed mmsegmentation-0.14.1\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Collecting easydict==1.9\n",
      "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6360 sha256=86cbab3aca404f9e9ec2436b97f5cc41d1d8e8e35341696776a0cc9f265b2794\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/d2/35/4c11d19a72280492846f4c4df975311a2bac475e8021f86c1d\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "  Attempting uninstall: easydict\n",
      "    Found existing installation: easydict 1.13\n",
      "    Uninstalling easydict-1.13:\n",
      "      Successfully uninstalled easydict-1.13\n",
      "Successfully installed easydict-1.9\n",
      "Collecting pyyaml==5.3\n",
      "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6.2.2\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
      "Collecting torch>=2.0.0 (from torchmetrics)\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.5)\n",
      "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.5.1\n",
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.5.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.14.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2024.9.11)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.66.5)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.24.7)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.5)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Collecting torch>=1.9.0 (from open_clip_torch)\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (10.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch) (58.0.4)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.5)\n",
      "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Installing collected packages: ftfy, torch, open_clip_torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.13.1 which is incompatible.\n",
      "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
      "torchmetrics 1.6.0 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ftfy-6.3.1 open_clip_torch-2.29.0 torch-1.13.1\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
      "Collecting python-hostlist\n",
      "  Downloading python-hostlist-2.2.1.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: python-hostlist\n",
      "  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-hostlist: filename=python_hostlist-2.2.1-py3-none-any.whl size=39614 sha256=295ce975538125d1381262e781b4b59d4147c93d3290a50ed43202e965fa1b87\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/a0/4e/057d4c6df390bb2f8c7c171df7bb39c124549a6b66cbe3480f\n",
      "Successfully built python-hostlist\n",
      "Installing collected packages: python-hostlist\n",
      "Successfully installed python-hostlist-2.2.1\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "with open('/kaggle/working/CAST/environment.yaml', 'r') as file:\n",
    "    env_data = yaml.safe_load(file)\n",
    "\n",
    "# Extract dependencies\n",
    "dependencies = env_data.get('dependencies', [])\n",
    "\n",
    "# Install pip dependencies\n",
    "for dep in dependencies:\n",
    "    if isinstance(dep, str):  # If it's a pip package\n",
    "        !pip install {dep}\n",
    "    elif isinstance(dep, dict) and 'pip' in dep:  # If it's a pip section\n",
    "        for pip_dep in dep['pip']:\n",
    "            !pip install {pip_dep}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:01:14.107202Z",
     "iopub.status.busy": "2024-12-28T13:01:14.106931Z",
     "iopub.status.idle": "2024-12-28T13:01:14.227994Z",
     "shell.execute_reply": "2024-12-28T13:01:14.227242Z",
     "shell.execute_reply.started": "2024-12-28T13:01:14.107181Z"
    },
    "id": "WJKr_Wy9cxAj",
    "outputId": "99282a08-46e2-4800-f4bd-32c499508990",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/content/CAST': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /content/CAST  # Check if cast.py is present\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/CAST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:01:14.229109Z",
     "iopub.status.busy": "2024-12-28T13:01:14.228834Z",
     "iopub.status.idle": "2024-12-28T13:02:03.884442Z",
     "shell.execute_reply": "2024-12-28T13:02:03.883324Z",
     "shell.execute_reply.started": "2024-12-28T13:01:14.229086Z"
    },
    "id": "9YfInpBqczfX",
    "outputId": "4b247f1e-916e-436d-f2c5-723f8ba35fd6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-28 13:01:14--  https://huggingface.co/twke/CAST/resolve/main/snapshots/moco/imagenet1k/cast_base/checkpoint_0099.pth.tar\n",
      "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.103, 18.239.50.80, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/07/97/07974173035d95e4743a789a61e1809d83f2e970a7a22886429996b77098f621/b254b05c9658b8cdc99bf87aeb9e77cb45bfe9d5035b7395a5274b89e73dd151?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint_0099.pth.tar%3B+filename%3D%22checkpoint_0099.pth.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1735650074&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTY1MDA3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzA3Lzk3LzA3OTc0MTczMDM1ZDk1ZTQ3NDNhNzg5YTYxZTE4MDlkODNmMmU5NzBhN2EyMjg4NjQyOTk5NmI3NzA5OGY2MjEvYjI1NGIwNWM5NjU4YjhjZGM5OWJmODdhZWI5ZTc3Y2I0NWJmZTlkNTAzNWI3Mzk1YTUyNzRiODllNzNkZDE1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=oAEAqt9-y2s4jwpFf8XjS8Zj3gD4wdegKlZKco5MrSJzoOfzCnjuPAqCfHVSDcN3ppo7z6n5oywikH3vhc14pTbJAqlTGUv5-E4lIdzSvZs3EGlMEGm-sOQiehDgr-QNKENqwQ1UHV8frMLYydH-nmOW1z0umyHTJa0RV6gJwlWL36YWCL6pK53uJN7TxfR4rEbc0nQPEyOZfR9X85DZBqzm9NxaMhGBa%7EGbeqMNEY4AQ2k44VkrQyUcj1nfzgFlF23iKOMZF%7EgjiDa4DQ6uLErDyL1n3HZrgBjhosJ0oung27Kk6-d52Bng3-9V-u3MjeyjrmknR3nN%7E7LzHwRdjw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2024-12-28 13:01:14--  https://cdn-lfs-us-1.hf.co/repos/07/97/07974173035d95e4743a789a61e1809d83f2e970a7a22886429996b77098f621/b254b05c9658b8cdc99bf87aeb9e77cb45bfe9d5035b7395a5274b89e73dd151?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint_0099.pth.tar%3B+filename%3D%22checkpoint_0099.pth.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1735650074&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTY1MDA3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzA3Lzk3LzA3OTc0MTczMDM1ZDk1ZTQ3NDNhNzg5YTYxZTE4MDlkODNmMmU5NzBhN2EyMjg4NjQyOTk5NmI3NzA5OGY2MjEvYjI1NGIwNWM5NjU4YjhjZGM5OWJmODdhZWI5ZTc3Y2I0NWJmZTlkNTAzNWI3Mzk1YTUyNzRiODllNzNkZDE1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=oAEAqt9-y2s4jwpFf8XjS8Zj3gD4wdegKlZKco5MrSJzoOfzCnjuPAqCfHVSDcN3ppo7z6n5oywikH3vhc14pTbJAqlTGUv5-E4lIdzSvZs3EGlMEGm-sOQiehDgr-QNKENqwQ1UHV8frMLYydH-nmOW1z0umyHTJa0RV6gJwlWL36YWCL6pK53uJN7TxfR4rEbc0nQPEyOZfR9X85DZBqzm9NxaMhGBa%7EGbeqMNEY4AQ2k44VkrQyUcj1nfzgFlF23iKOMZF%7EgjiDa4DQ6uLErDyL1n3HZrgBjhosJ0oung27Kk6-d52Bng3-9V-u3MjeyjrmknR3nN%7E7LzHwRdjw__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.69.55, 18.239.69.100, 18.239.69.53, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.69.55|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2076601354 (1.9G) [application/x-tar]\n",
      "Saving to: ‘cast_base_checkpoint.pth.tar’\n",
      "\n",
      "cast_base_checkpoin 100%[===================>]   1.93G  40.4MB/s    in 49s     \n",
      "\n",
      "2024-12-28 13:02:03 (40.3 MB/s) - ‘cast_base_checkpoint.pth.tar’ saved [2076601354/2076601354]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O  cast_base_checkpoint.pth.tar https://huggingface.co/twke/CAST/resolve/main/snapshots/moco/imagenet1k/cast_base/checkpoint_0099.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:11.960395Z",
     "iopub.status.busy": "2024-12-28T13:02:11.960173Z",
     "iopub.status.idle": "2024-12-28T13:02:15.642395Z",
     "shell.execute_reply": "2024-12-28T13:02:15.641462Z",
     "shell.execute_reply.started": "2024-12-28T13:02:11.960376Z"
    },
    "id": "fESVsYYVc7wL",
    "outputId": "a1196735-cc97-4b47-e39b-e14520b7e001",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    }
   ],
   "source": [
    "from cast_models.cast import cast_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:15.643933Z",
     "iopub.status.busy": "2024-12-28T13:02:15.643365Z",
     "iopub.status.idle": "2024-12-28T13:02:15.978465Z",
     "shell.execute_reply": "2024-12-28T13:02:15.977795Z",
     "shell.execute_reply.started": "2024-12-28T13:02:15.643873Z"
    },
    "id": "B8hDkYDdc9bB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import skimage.color as sk_color\n",
    "import skimage.morphology as sk_morph\n",
    "import scipy.io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append('/kaggle/working/CAST/moco-v3/')\n",
    "import suppix_utils.datasets_seeds as datasets\n",
    "\n",
    "sys.path.append('/kaggle/working/CAST/')\n",
    "import cast_models.cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:15.979727Z",
     "iopub.status.busy": "2024-12-28T13:02:15.979229Z",
     "iopub.status.idle": "2024-12-28T13:02:15.983310Z",
     "shell.execute_reply": "2024-12-28T13:02:15.982527Z",
     "shell.execute_reply.started": "2024-12-28T13:02:15.979696Z"
    },
    "id": "CRofa1i_fWE3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/working/CAST/notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:15.984278Z",
     "iopub.status.busy": "2024-12-28T13:02:15.984030Z",
     "iopub.status.idle": "2024-12-28T13:02:17.677464Z",
     "shell.execute_reply": "2024-12-28T13:02:17.676293Z",
     "shell.execute_reply.started": "2024-12-28T13:02:15.984257Z"
    },
    "id": "G6pmp6t4dAVf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from open_clip import create_model_and_transforms, get_tokenizer\n",
    "\n",
    "import numpy as np\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "from dataset import PartImageNetWithMask, PredictedMask\n",
    "from utils import TextFeatures, get_masked_pred_c, get_masked_pred_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:17.679398Z",
     "iopub.status.busy": "2024-12-28T13:02:17.678711Z",
     "iopub.status.idle": "2024-12-28T13:02:23.326250Z",
     "shell.execute_reply": "2024-12-28T13:02:23.325487Z",
     "shell.execute_reply.started": "2024-12-28T13:02:17.679363Z"
    },
    "id": "EEdJ8AUwdCC2",
    "outputId": "881a9461-56fc-452f-8b52-cff5a9e0509a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS_NAME = 'cast_base'\n",
    "CHECKPOINT_PATH = '/kaggle/working/cast_base_checkpoint.pth.tar'\n",
    "\n",
    "model = cast_models.cast.__dict__[MODEL_CLASS_NAME]().cuda()\n",
    "ckpt = torch.load(CHECKPOINT_PATH, map_location='cuda:0')\n",
    "state_dict = {k[len('module.base_encoder.'):]: v for k, v in ckpt['state_dict'].items()\n",
    "              if 'module.base_encoder.' in k and 'head' not in k}\n",
    "msg = model.load_state_dict(state_dict, strict=False)\n",
    "print(msg)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:23.327360Z",
     "iopub.status.busy": "2024-12-28T13:02:23.327082Z",
     "iopub.status.idle": "2024-12-28T13:02:23.330810Z",
     "shell.execute_reply": "2024-12-28T13:02:23.329993Z",
     "shell.execute_reply.started": "2024-12-28T13:02:23.327339Z"
    },
    "id": "Zw6GBbNsdDlW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/working/CAST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:02:23.332019Z",
     "iopub.status.busy": "2024-12-28T13:02:23.331718Z",
     "iopub.status.idle": "2024-12-28T13:02:39.520706Z",
     "shell.execute_reply": "2024-12-28T13:02:39.519777Z",
     "shell.execute_reply.started": "2024-12-28T13:02:23.331991Z"
    },
    "id": "NVpwpF0gdGHR",
    "outputId": "b9a3aacc-b7b3-47a3-db36-7972719abacb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data restructuring completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source and target directories\n",
    "source_images = \"/kaggle/input/partimagenet-ood/val/val\"\n",
    "source_annotations = \"/kaggle/input/partimagenet-ood/val.json\"\n",
    "target_base = \"/kaggle/working/CAST/data/PartImageNet\"\n",
    "target_images = os.path.join(target_base, \"images/val\")\n",
    "target_annotations = os.path.join(target_base, \"annotations\")\n",
    "\n",
    "# Create the target directories\n",
    "os.makedirs(target_images, exist_ok=True)\n",
    "os.makedirs(target_annotations, exist_ok=True)\n",
    "\n",
    "# Move image folders\n",
    "for folder in os.listdir(source_images):\n",
    "    src_folder = os.path.join(source_images, folder)\n",
    "    dest_folder = os.path.join(target_images, folder)\n",
    "    shutil.copytree(src_folder, dest_folder)\n",
    "\n",
    "# Move the annotations file\n",
    "shutil.copy(source_annotations, os.path.join(target_annotations, \"val.json\"))\n",
    "\n",
    "print(\"Data restructuring completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:05:07.043512Z",
     "iopub.status.busy": "2024-12-28T13:05:07.043221Z",
     "iopub.status.idle": "2024-12-28T13:05:07.051252Z",
     "shell.execute_reply": "2024-12-28T13:05:07.050624Z",
     "shell.execute_reply.started": "2024-12-28T13:05:07.043491Z"
    },
    "id": "K7pEybDDdWQo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move model to CPU (if it's not already)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:05:05.142358Z",
     "iopub.status.busy": "2024-12-28T13:05:05.142029Z",
     "iopub.status.idle": "2024-12-28T13:05:05.147803Z",
     "shell.execute_reply": "2024-12-28T13:05:05.146848Z",
     "shell.execute_reply.started": "2024-12-28T13:05:05.142331Z"
    },
    "id": "-MssGL_a7CR9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '/kaggle/working/CAST/data/PartImageNet/images/val/'\n",
    "\n",
    "\n",
    "class ReturnIndexDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, idx):\n",
    "        img, seg, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n",
    "        return img, seg, lab, idx\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:05:10.160900Z",
     "iopub.status.busy": "2024-12-28T13:05:10.160609Z",
     "iopub.status.idle": "2024-12-28T13:05:10.169183Z",
     "shell.execute_reply": "2024-12-28T13:05:10.168318Z",
     "shell.execute_reply.started": "2024-12-28T13:05:10.160879Z"
    },
    "id": "ynQRm8J78D50",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_values():\n",
    "    if accs_c and accs_f:  # Check if there are values to compute the mean\n",
    "        print(\"{:d}/{:d}    {:.2f}/{:.2f}\".format(\n",
    "            index + 1, len(dataset),\n",
    "            np.mean(accs_c) * 100, np.mean(accs_f) * 100,\n",
    "        ))\n",
    "\n",
    "jaccard_c = JaccardIndex(task=\"multiclass\", num_classes=11+1)\n",
    "jaccard_f = JaccardIndex(task=\"multiclass\", num_classes=40+1)\n",
    "\n",
    "accs_c, accs_f = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING 256, 384, 512 AS NUMBER OF SEGMENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-28T13:05:40.404181Z",
     "iopub.status.busy": "2024-12-28T13:05:40.403732Z",
     "iopub.status.idle": "2024-12-28T13:47:49.942791Z",
     "shell.execute_reply": "2024-12-28T13:47:49.941810Z",
     "shell.execute_reply.started": "2024-12-28T13:05:40.404145Z"
    },
    "id": "j0jxwkYmfwR9",
    "outputId": "21fcac71-aba1-43c3-e573-1e771f790701",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with n_segments = 256\n",
      "Processing with n_segments = 384\n",
      "Processing with n_segments = 512\n"
     ]
    }
   ],
   "source": [
    "n_segments_list = [256, 384, 512]\n",
    "\n",
    "for n_segments in n_segments_list:\n",
    "\n",
    "    DATA_ROOT = '/kaggle/working/CAST/data/PartImageNet/images/val/'\n",
    "    print(f\"Processing with n_segments = {n_segments}\")\n",
    "    SAVE_ROOT = '../pred_segs/{n_segments}/'\n",
    "\n",
    "    # Reinitialize the dataset with the current `n_segments` value\n",
    "    train_dataset = ReturnIndexDataset(\n",
    "        root=DATA_ROOT,\n",
    "        transform=transforms.Compose(augmentation),\n",
    "        n_segments=n_segments,\n",
    "        compactness=10.0,\n",
    "        blur_ops=None,\n",
    "        scale_factor=1.0\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    # Iterate over the DataLoader\n",
    "\n",
    "    for i, (img, suppixel, label, img_inds) in enumerate(train_loader):\n",
    "        img = img.cpu() # input images\n",
    "        suppixel = suppixel.cpu() # superpixels\n",
    "\n",
    "        # Forward pass to return intermediate groupings\n",
    "        intermediates = model.forward_features(img, suppixel)\n",
    "\n",
    "        # Aggregate groupings from fine to coarse levels\n",
    "        segmentations = {}\n",
    "        prev_labels = {}\n",
    "        # Iterate through the finest to the coarsest scales\n",
    "        for level in [1, 2, 3, 4]:\n",
    "            # Iterate through the mini-batch\n",
    "            for b in range(img.shape[0]):\n",
    "                # Grouping logit for the current level\n",
    "                logit = intermediates['logit{:d}'.format(level)][b]\n",
    "                label = torch.argmax(logit, dim=-1).detach()\n",
    "                if level == 1 and len(label) < 196:\n",
    "                    npad = torch.unique(suppixel).shape[0] - logit.shape[0]\n",
    "                    label = torch.concat([label, torch.tensor([label[-1]] * npad, device=label.device)])\n",
    "\n",
    "                # Gather coarser grouping at the current level\n",
    "                # The level-1 grouping index for each level-0 group is [1, 2, 2, 0, 1, 1, 0]\n",
    "                # The level-2 grouping index for each level-1 group is [0, 1, 0]\n",
    "                # We infer the level-2 grouping for each level-0 group as [1, 0, 0, 0, 1, 1, 0]\n",
    "                if level > 1:\n",
    "                    prev_label = prev_labels['level{:d}'.format(level-1)][b]\n",
    "                    label = torch.gather(label, 0, prev_label.view(-1).long())\n",
    "\n",
    "                if prev_labels.get('level{:d}'.format(level), None) is None:\n",
    "                    prev_labels['level{:d}'.format(level)] = []\n",
    "                prev_labels['level{:d}'.format(level)].append(label)\n",
    "\n",
    "                # Gather groupings for each superpixel\n",
    "                suppixel = torch.clamp(suppixel, 0, label.size(0) - 1)  # Clamp to the size of label\n",
    "\n",
    "                label = torch.gather(label, 0, suppixel[b].view(-1))\n",
    "\n",
    "                label = label.view(suppixel.shape[-2:])\n",
    "\n",
    "                # Save segmentations by levels\n",
    "                save_root = os.path.join(SAVE_ROOT, MODEL_CLASS_NAME, 'level{:d}'.format(level))\n",
    "                os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "                file_name = train_dataset.samples[img_inds[b]][0]\n",
    "                file_name = file_name.split('/')[-1].split('.')[0]\n",
    "                with open(os.path.join(save_root, '{}.npy'.format(file_name)), 'wb') as f:\n",
    "                    np.save(f, label.cpu().data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T13:51:59.235238Z",
     "iopub.status.busy": "2024-12-28T13:51:59.234932Z",
     "iopub.status.idle": "2024-12-28T14:36:15.935779Z",
     "shell.execute_reply": "2024-12-28T14:36:15.934894Z",
     "shell.execute_reply.started": "2024-12-28T13:51:59.235214Z"
    },
    "id": "0vhbXduW6smu",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with n_segments = 256\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "100/2957    33.82/14.69\n",
      "200/2957    32.14/14.21\n",
      "300/2957    29.32/12.84\n",
      "400/2957    27.38/11.95\n",
      "500/2957    26.30/11.77\n",
      "600/2957    26.64/12.85\n",
      "700/2957    26.71/13.50\n",
      "800/2957    26.65/13.94\n",
      "900/2957    26.42/14.53\n",
      "1000/2957    26.47/14.42\n",
      "1100/2957    26.15/14.04\n",
      "1200/2957    25.99/13.84\n",
      "1300/2957    25.98/13.71\n",
      "1400/2957    26.26/13.67\n",
      "1500/2957    26.58/13.66\n",
      "1600/2957    26.82/13.65\n",
      "1700/2957    27.64/13.77\n",
      "1800/2957    28.30/13.78\n",
      "1900/2957    28.79/13.76\n",
      "2000/2957    29.40/13.84\n",
      "2100/2957    29.60/13.81\n",
      "2200/2957    30.09/13.91\n",
      "2300/2957    30.42/13.94\n",
      "2400/2957    30.67/13.97\n",
      "2500/2957    30.90/13.97\n",
      "2600/2957    31.16/13.96\n",
      "2700/2957    31.36/13.98\n",
      "2800/2957    31.61/14.03\n",
      "2900/2957    31.50/14.04\n",
      "2957/2957    31.48/14.11\n",
      "Processing with n_segments = 384\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "100/2957    31.56/14.12\n",
      "200/2957    31.52/14.11\n",
      "300/2957    31.28/13.99\n",
      "400/2957    30.99/13.85\n",
      "500/2957    30.73/13.77\n",
      "600/2957    30.67/13.89\n",
      "700/2957    30.57/13.99\n",
      "800/2957    30.45/14.07\n",
      "900/2957    30.30/14.21\n",
      "1000/2957    30.22/14.19\n",
      "1100/2957    30.04/14.09\n",
      "1200/2957    29.90/14.03\n",
      "1300/2957    29.80/13.98\n",
      "1400/2957    29.80/13.97\n",
      "1500/2957    29.83/13.96\n",
      "1600/2957    29.85/13.95\n",
      "1700/2957    30.08/13.98\n",
      "1800/2957    30.28/13.98\n",
      "1900/2957    30.43/13.97\n",
      "2000/2957    30.64/14.00\n",
      "2100/2957    30.70/13.98\n",
      "2200/2957    30.89/14.02\n",
      "2300/2957    31.02/14.03\n",
      "2400/2957    31.12/14.05\n",
      "2500/2957    31.22/14.04\n",
      "2600/2957    31.33/14.04\n",
      "2700/2957    31.42/14.05\n",
      "2800/2957    31.54/14.07\n",
      "2900/2957    31.49/14.07\n",
      "2957/2957    31.48/14.11\n",
      "Processing with n_segments = 512\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "100/2957    31.52/14.12\n",
      "200/2957    31.50/14.11\n",
      "300/2957    31.38/14.04\n",
      "400/2957    31.22/13.97\n",
      "500/2957    31.08/13.92\n",
      "600/2957    31.04/13.99\n",
      "700/2957    30.98/14.04\n",
      "800/2957    30.91/14.09\n",
      "900/2957    30.81/14.16\n",
      "1000/2957    30.76/14.15\n",
      "1100/2957    30.65/14.10\n",
      "1200/2957    30.56/14.06\n",
      "1300/2957    30.49/14.03\n",
      "1400/2957    30.48/14.02\n",
      "1500/2957    30.49/14.02\n",
      "1600/2957    30.49/14.01\n",
      "1700/2957    30.63/14.03\n",
      "1800/2957    30.74/14.03\n",
      "1900/2957    30.83/14.02\n",
      "2000/2957    30.96/14.04\n",
      "2100/2957    30.99/14.03\n",
      "2200/2957    31.10/14.05\n",
      "2300/2957    31.19/14.06\n",
      "2400/2957    31.25/14.07\n",
      "2500/2957    31.31/14.07\n",
      "2600/2957    31.39/14.06\n",
      "2700/2957    31.44/14.07\n",
      "2800/2957    31.52/14.08\n",
      "2900/2957    31.49/14.08\n",
      "2957/2957    31.48/14.11\n"
     ]
    }
   ],
   "source": [
    "n_segments_list = [256, 384, 512]\n",
    "\n",
    "for n_segments in n_segments_list:\n",
    "        print(f\"Processing with n_segments = {n_segments}\")\n",
    "\n",
    "        device = \"cuda:0\"\n",
    "        torch.cuda.set_device(device)\n",
    "\n",
    "        clip, _, clip_transform = create_model_and_transforms('ViT-B-16', pretrained='openai')\n",
    "        tokenizer = get_tokenizer('ViT-B-16')\n",
    "\n",
    "        clip = clip.to(device)\n",
    "\n",
    "        normalize = clip_transform.transforms[-1]\n",
    "        img_transform = T.Compose([\n",
    "            T.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "            T.CenterCrop([224, 224]),\n",
    "        ])\n",
    "        seg_transform = T.Compose([\n",
    "            T.Resize(224, interpolation=InterpolationMode.NEAREST),\n",
    "            T.CenterCrop([224, 224]),\n",
    "        ])\n",
    "\n",
    "        DATA_ROOT = '/kaggle/working/CAST/data/PartImageNet/'\n",
    "        SAVE_ROOT = '../pred_segs/{n_segments}/'\n",
    "\n",
    "        model_name = \"cast_base\"\n",
    "        # model_name = \"vit_base\"\n",
    "\n",
    "        img_root = os.path.join(DATA_ROOT, 'images/val')\n",
    "        ano_root = os.path.join(DATA_ROOT, 'annotations/val.json')\n",
    "\n",
    "        pred_c_root = os.path.join(SAVE_ROOT, model_name, 'level4')\n",
    "        pred_f_root = os.path.join(SAVE_ROOT, model_name, 'level3')\n",
    "\n",
    "        # Output: image, seg_c, seg_f\n",
    "        dataset = PartImageNetWithMask(img_root, ano_root, clip_transform, seg_transform)\n",
    "\n",
    "        # Predicted segments by CAST or ViT\n",
    "        mask_dataset_c = PredictedMask(pred_c_root, ano_root)\n",
    "        mask_dataset_f = PredictedMask(pred_f_root, ano_root)\n",
    "\n",
    "\n",
    "        text_features = TextFeatures(clip, tokenizer,\n",
    "                                    dataset.classname_c,\n",
    "                                    dataset.classname_f)\n",
    "        for index in range(len(dataset)):\n",
    "            try:\n",
    "                img, seg_c, seg_f = dataset[index]\n",
    "\n",
    "                mask_c = mask_dataset_c[index]\n",
    "                mask_f = mask_dataset_f[index]\n",
    "\n",
    "                pred_c = get_masked_pred_c(clip, text_features, img, mask_c)\n",
    "                pred_f = get_masked_pred_f(clip, text_features, img, mask_f, pred_c)\n",
    "\n",
    "                # Ensure predictions are valid before calculating Jaccard index\n",
    "                if pred_c is not None and pred_f is not None:\n",
    "                    accs_c.append(jaccard_c(pred_c, seg_c).item())\n",
    "                    accs_f.append(jaccard_f(pred_f, seg_f).item())\n",
    "                else:\n",
    "                    print(f\"Skipping index {index}: Invalid prediction\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}: {e}\")\n",
    "\n",
    "            if (index + 1) % 100 == 0:\n",
    "                print_values()\n",
    "\n",
    "        index = len(dataset) - 1\n",
    "        print_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING 768, 1024 AS NUMBER OF SEGMENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T14:39:00.627664Z",
     "iopub.status.busy": "2024-12-28T14:39:00.627389Z",
     "iopub.status.idle": "2024-12-28T15:24:05.683639Z",
     "shell.execute_reply": "2024-12-28T15:24:05.682851Z",
     "shell.execute_reply.started": "2024-12-28T14:39:00.627642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with n_segments = 768\n",
      "Processing with n_segments = 1024\n"
     ]
    }
   ],
   "source": [
    "n_segments_list = [768, 1024]\n",
    "\n",
    "for n_segments in n_segments_list:\n",
    "\n",
    "    DATA_ROOT = '/kaggle/working/CAST/data/PartImageNet/images/val/'\n",
    "    print(f\"Processing with n_segments = {n_segments}\")\n",
    "    SAVE_ROOT = '../pred_segs/{n_segments}/'\n",
    "\n",
    "    # Reinitialize the dataset with the current `n_segments` value\n",
    "    train_dataset = ReturnIndexDataset(\n",
    "        root=DATA_ROOT,\n",
    "        transform=transforms.Compose(augmentation),\n",
    "        n_segments=n_segments,\n",
    "        compactness=10.0,\n",
    "        blur_ops=None,\n",
    "        scale_factor=1.0\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    # Iterate over the DataLoader\n",
    "\n",
    "    for i, (img, suppixel, label, img_inds) in enumerate(train_loader):\n",
    "        img = img.cpu() # input images\n",
    "        suppixel = suppixel.cpu() # superpixels\n",
    "\n",
    "        # Forward pass to return intermediate groupings\n",
    "        intermediates = model.forward_features(img, suppixel)\n",
    "\n",
    "        # Aggregate groupings from fine to coarse levels\n",
    "        segmentations = {}\n",
    "        prev_labels = {}\n",
    "        # Iterate through the finest to the coarsest scales\n",
    "        for level in [1, 2, 3, 4]:\n",
    "            # Iterate through the mini-batch\n",
    "            for b in range(img.shape[0]):\n",
    "                # Grouping logit for the current level\n",
    "                logit = intermediates['logit{:d}'.format(level)][b]\n",
    "                label = torch.argmax(logit, dim=-1).detach()\n",
    "                if level == 1 and len(label) < 196:\n",
    "                    npad = torch.unique(suppixel).shape[0] - logit.shape[0]\n",
    "                    label = torch.concat([label, torch.tensor([label[-1]] * npad, device=label.device)])\n",
    "\n",
    "                # Gather coarser grouping at the current level\n",
    "                # The level-1 grouping index for each level-0 group is [1, 2, 2, 0, 1, 1, 0]\n",
    "                # The level-2 grouping index for each level-1 group is [0, 1, 0]\n",
    "                # We infer the level-2 grouping for each level-0 group as [1, 0, 0, 0, 1, 1, 0]\n",
    "                if level > 1:\n",
    "                    prev_label = prev_labels['level{:d}'.format(level-1)][b]\n",
    "                    label = torch.gather(label, 0, prev_label.view(-1).long())\n",
    "\n",
    "                if prev_labels.get('level{:d}'.format(level), None) is None:\n",
    "                    prev_labels['level{:d}'.format(level)] = []\n",
    "                prev_labels['level{:d}'.format(level)].append(label)\n",
    "\n",
    "                # Gather groupings for each superpixel\n",
    "                suppixel = torch.clamp(suppixel, 0, label.size(0) - 1)  # Clamp to the size of label\n",
    "\n",
    "                label = torch.gather(label, 0, suppixel[b].view(-1))\n",
    "\n",
    "                label = label.view(suppixel.shape[-2:])\n",
    "\n",
    "                # Save segmentations by levels\n",
    "                save_root = os.path.join(SAVE_ROOT, MODEL_CLASS_NAME, 'level{:d}'.format(level))\n",
    "                os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "                file_name = train_dataset.samples[img_inds[b]][0]\n",
    "                file_name = file_name.split('/')[-1].split('.')[0]\n",
    "                with open(os.path.join(save_root, '{}.npy'.format(file_name)), 'wb') as f:\n",
    "                    np.save(f, label.cpu().data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T15:24:05.685050Z",
     "iopub.status.busy": "2024-12-28T15:24:05.684763Z",
     "iopub.status.idle": "2024-12-28T15:53:58.000105Z",
     "shell.execute_reply": "2024-12-28T15:53:57.999289Z",
     "shell.execute_reply.started": "2024-12-28T15:24:05.685029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with n_segments = 768\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "100/2957    31.45/14.10\n",
      "200/2957    31.36/14.07\n",
      "300/2957    31.28/14.03\n",
      "400/2957    31.18/13.99\n",
      "500/2957    31.09/13.96\n",
      "600/2957    31.02/13.98\n",
      "700/2957    30.95/14.00\n",
      "800/2957    30.88/14.01\n",
      "900/2957    30.78/14.02\n",
      "1000/2957    30.72/14.00\n",
      "1100/2957    30.63/13.97\n",
      "1200/2957    30.59/13.96\n",
      "1300/2957    30.55/13.94\n",
      "1400/2957    30.52/13.95\n",
      "1500/2957    30.50/13.95\n",
      "1600/2957    30.49/13.95\n",
      "1700/2957    30.54/13.95\n",
      "1800/2957    30.57/13.94\n",
      "1900/2957    30.61/13.94\n",
      "2000/2957    30.65/13.93\n",
      "2100/2957    30.63/13.92\n",
      "2200/2957    30.63/13.93\n",
      "2300/2957    30.59/13.92\n",
      "2400/2957    30.61/13.92\n",
      "2500/2957    30.58/13.92\n",
      "2600/2957    30.57/13.90\n",
      "2700/2957    30.55/13.90\n",
      "2800/2957    30.55/13.90\n",
      "2900/2957    30.55/13.91\n",
      "2957/2957    30.55/13.94\n",
      "Processing with n_segments = 1024\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "100/2957    30.53/13.93\n",
      "200/2957    30.48/13.91\n",
      "300/2957    30.42/13.89\n",
      "400/2957    30.35/13.85\n",
      "500/2957    30.29/13.84\n",
      "600/2957    30.24/13.85\n",
      "700/2957    30.19/13.87\n",
      "800/2957    30.15/13.88\n",
      "900/2957    30.08/13.88\n",
      "1000/2957    30.04/13.87\n",
      "1100/2957    29.98/13.85\n",
      "1200/2957    29.95/13.84\n",
      "1300/2957    29.92/13.83\n",
      "1400/2957    29.91/13.83\n",
      "1500/2957    29.89/13.84\n",
      "1600/2957    29.89/13.84\n",
      "1700/2957    29.94/13.84\n",
      "1800/2957    29.96/13.84\n",
      "1900/2957    30.00/13.83\n",
      "2000/2957    30.03/13.83\n",
      "2100/2957    30.02/13.82\n",
      "2200/2957    30.02/13.82\n",
      "2300/2957    29.99/13.82\n",
      "2400/2957    30.01/13.82\n",
      "2500/2957    30.00/13.82\n",
      "2600/2957    29.99/13.81\n",
      "2700/2957    29.99/13.81\n",
      "2800/2957    29.99/13.80\n",
      "2900/2957    29.99/13.82\n",
      "2957/2957    29.99/13.84\n"
     ]
    }
   ],
   "source": [
    "n_segments_list = [768, 1024]\n",
    "\n",
    "for n_segments in n_segments_list:\n",
    "        print(f\"Processing with n_segments = {n_segments}\")\n",
    "\n",
    "        device = \"cuda:0\"\n",
    "        torch.cuda.set_device(device)\n",
    "\n",
    "        clip, _, clip_transform = create_model_and_transforms('ViT-B-16', pretrained='openai')\n",
    "        tokenizer = get_tokenizer('ViT-B-16')\n",
    "\n",
    "        clip = clip.to(device)\n",
    "\n",
    "        normalize = clip_transform.transforms[-1]\n",
    "        img_transform = T.Compose([\n",
    "            T.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "            T.CenterCrop([224, 224]),\n",
    "        ])\n",
    "        seg_transform = T.Compose([\n",
    "            T.Resize(224, interpolation=InterpolationMode.NEAREST),\n",
    "            T.CenterCrop([224, 224]),\n",
    "        ])\n",
    "\n",
    "        DATA_ROOT = '/kaggle/working/CAST/data/PartImageNet/'\n",
    "        SAVE_ROOT = '../pred_segs/{n_segments}/'\n",
    "\n",
    "        model_name = \"cast_base\"\n",
    "        # model_name = \"vit_base\"\n",
    "\n",
    "        img_root = os.path.join(DATA_ROOT, 'images/val')\n",
    "        ano_root = os.path.join(DATA_ROOT, 'annotations/val.json')\n",
    "\n",
    "        pred_c_root = os.path.join(SAVE_ROOT, model_name, 'level4')\n",
    "        pred_f_root = os.path.join(SAVE_ROOT, model_name, 'level3')\n",
    "\n",
    "        # Output: image, seg_c, seg_f\n",
    "        dataset = PartImageNetWithMask(img_root, ano_root, clip_transform, seg_transform)\n",
    "\n",
    "        # Predicted segments by CAST or ViT\n",
    "        mask_dataset_c = PredictedMask(pred_c_root, ano_root)\n",
    "        mask_dataset_f = PredictedMask(pred_f_root, ano_root)\n",
    "\n",
    "\n",
    "        text_features = TextFeatures(clip, tokenizer,\n",
    "                                    dataset.classname_c,\n",
    "                                    dataset.classname_f)\n",
    "        for index in range(len(dataset)):\n",
    "            try:\n",
    "                img, seg_c, seg_f = dataset[index]\n",
    "\n",
    "                mask_c = mask_dataset_c[index]\n",
    "                mask_f = mask_dataset_f[index]\n",
    "\n",
    "                pred_c = get_masked_pred_c(clip, text_features, img, mask_c)\n",
    "                pred_f = get_masked_pred_f(clip, text_features, img, mask_f, pred_c)\n",
    "\n",
    "                # Ensure predictions are valid before calculating Jaccard index\n",
    "                if pred_c is not None and pred_f is not None:\n",
    "                    accs_c.append(jaccard_c(pred_c, seg_c).item())\n",
    "                    accs_f.append(jaccard_f(pred_f, seg_f).item())\n",
    "                else:\n",
    "                    print(f\"Skipping index {index}: Invalid prediction\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {index}: {e}\")\n",
    "\n",
    "            if (index + 1) % 100 == 0:\n",
    "                print_values()\n",
    "\n",
    "        index = len(dataset) - 1\n",
    "        print_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6387967,
     "sourceId": 10318023,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "22525dc97027415c9721c29bcb54b39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40622c4d9a3c44cf8bf556399cd3dcd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49b38b18d5534bc8801618ce5b4294b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fd3308e9e694d70b2402ae8a399ebe4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60f2d5c5b61c4383959f3aeee10ab12a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fd3308e9e694d70b2402ae8a399ebe4",
      "placeholder": "​",
      "style": "IPY_MODEL_22525dc97027415c9721c29bcb54b39e",
      "value": " 599M/599M [00:07&lt;00:00, 81.5MB/s]"
     }
    },
    "7f3863ac6d5d476b9cc6d54f41b27023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "929ae3e2c22a40bdb52c19cfa626d94f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba3a8d86171742f2bf252393a971968c",
      "max": 598516980,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49b38b18d5534bc8801618ce5b4294b7",
      "value": 598516980
     }
    },
    "9643d9b672474706b3f16d14e1d0af08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c26f98e9eb944ce8b72a3b78411b189c",
      "placeholder": "​",
      "style": "IPY_MODEL_40622c4d9a3c44cf8bf556399cd3dcd8",
      "value": "open_clip_model.safetensors: 100%"
     }
    },
    "ba3a8d86171742f2bf252393a971968c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c26f98e9eb944ce8b72a3b78411b189c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5481605d88c41f3bc38932668be2f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9643d9b672474706b3f16d14e1d0af08",
       "IPY_MODEL_929ae3e2c22a40bdb52c19cfa626d94f",
       "IPY_MODEL_60f2d5c5b61c4383959f3aeee10ab12a"
      ],
      "layout": "IPY_MODEL_7f3863ac6d5d476b9cc6d54f41b27023"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
