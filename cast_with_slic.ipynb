{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suG621BCcrxB",
        "outputId": "4fad53e5-9e6c-4715-bc22-6e33750dc358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CAST'...\n",
            "remote: Enumerating objects: 1289, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
            "remote: Total 1289 (delta 131), reused 300 (delta 125), pack-reused 976 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1289/1289), 41.99 MiB | 8.49 MiB/s, done.\n",
            "Resolving deltas: 100% (582/582), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/twke18/CAST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1+cu116 --index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install dgl==1.1.3+cu121 -f https://data.dgl.ai/wheels/cu121/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWIRpCBGctiH",
        "outputId": "b7ca8bf6-b55c-40d8-f84c-df862e476cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.10.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2->torchdata) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (3.0.2)\n",
            "Downloading torchdata-0.10.1-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata\n",
            "Successfully installed torchdata-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZaVFLu3LcvJ3",
        "outputId": "66fb379e-139c-4ee9-d4e5-8d7034113bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'python=3.9': Expected end or semicolon (after name and no valid version specifier)\n",
            "    python=3.9\n",
            "          ^\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "\u001b[31mERROR: Invalid requirement: 'pytorch-cuda=11.6': Expected end or semicolon (after name and no valid version specifier)\n",
            "    pytorch-cuda=11.6\n",
            "                ^\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.13.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torchvision==0.14.1\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.32.3)\n",
            "Collecting torch==1.13.1 (from torchvision==0.14.1)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (11.0.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2024.12.14)\n",
            "Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (1.13.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (0.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4->timm==0.4.12) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2024.12.14)\n",
            "Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.12\n",
            "    Uninstalling timm-1.0.12:\n",
            "      Successfully uninstalled timm-1.0.12\n",
            "Successfully installed timm-0.4.12\n",
            "Collecting setuptools==58.0.4\n",
            "  Downloading setuptools-58.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading setuptools-58.0.4-py3-none-any.whl (816 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.5/816.5 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.20.0 requires setuptools>=60.0.0, but you have setuptools 58.0.4 which is incompatible.\n",
            "pytensor 2.26.4 requires setuptools>=59.0.0, but you have setuptools 58.0.4 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-58.0.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ad7ab44c97fc44a292c96d2bed9f8267",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (58.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting hostlist\n",
            "  Downloading hostlist-1.4.8-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hostlist) (6.0.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from hostlist) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hostlist) (2.32.3)\n",
            "Collecting cherrypy (from hostlist)\n",
            "  Downloading CherryPy-18.10.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (from hostlist) (3.1.43)\n",
            "Collecting ansible-cmdb (from hostlist)\n",
            "  Downloading ansible_cmdb-1.31-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting typing (from hostlist)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako (from ansible-cmdb->hostlist)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting ushlex (from ansible-cmdb->hostlist)\n",
            "  Downloading ushlex-0.99.1.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonxs (from ansible-cmdb->hostlist)\n",
            "  Downloading jsonxs-0.6.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cheroot>=8.2.1 (from cherrypy->hostlist)\n",
            "  Downloading cheroot-10.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting portend>=2.1.1 (from cherrypy->hostlist)\n",
            "  Downloading portend-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->hostlist) (10.5.0)\n",
            "Collecting zc.lockfile (from cherrypy->hostlist)\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting jaraco.collections (from cherrypy->hostlist)\n",
            "  Downloading jaraco.collections-5.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython->hostlist) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->hostlist) (2024.12.14)\n",
            "Collecting jaraco.functools (from cheroot>=8.2.1->cherrypy->hostlist)\n",
            "  Downloading jaraco.functools-4.1.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython->hostlist) (5.0.1)\n",
            "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->hostlist)\n",
            "  Downloading tempora-5.7.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting jaraco.text (from jaraco.collections->cherrypy->hostlist)\n",
            "  Downloading jaraco.text-4.0.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->ansible-cmdb->hostlist) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->hostlist) (58.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->hostlist) (2.8.2)\n",
            "Collecting jaraco.context>=4.1 (from jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
            "  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting autocommand (from jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting backports.tarfile (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->hostlist)\n",
            "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->tempora>=1.8->portend>=2.1.1->cherrypy->hostlist) (1.17.0)\n",
            "Downloading hostlist-1.4.8-py3-none-any.whl (34 kB)\n",
            "Downloading ansible_cmdb-1.31-py2.py3-none-any.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading CherryPy-18.10.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.8/349.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cheroot-10.0.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portend-3.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading jaraco.collections-5.1.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Downloading tempora-5.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading jaraco.functools-4.1.0-py3-none-any.whl (10 kB)\n",
            "Downloading jaraco.text-4.0.0-py3-none-any.whl (11 kB)\n",
            "Downloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
            "Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
            "Building wheels for collected packages: typing, jsonxs, ushlex\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26323 sha256=dfd3f3ff7b85af6a8c6e5feaedf7bc134d0fcbad24809eb60a675ab53aaa14a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
            "  Building wheel for jsonxs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonxs: filename=jsonxs-0.6-py3-none-any.whl size=4676 sha256=d3ce37b2cbc43a4f0a95e3cee1e294b9707deba844dd5fdf32dcc054b0b67604\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/81/b1/a3db92b8e5b7691128d659cbe4e12bffd54ece2748be6295a2\n",
            "  Building wheel for ushlex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ushlex: filename=ushlex-0.99.1-py3-none-any.whl size=4416 sha256=92900f31a14a026d3f62a68f9fa70a7ea568698b2bfd04a9ddc4af705c4e7a17\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/e4/80/4de44668798392eb2f5b24f0130df2f5d28b43cb256bf9c1f9\n",
            "Successfully built typing jsonxs ushlex\n",
            "Installing collected packages: ushlex, jsonxs, zc.lockfile, typing, mako, jaraco.functools, backports.tarfile, autocommand, tempora, jaraco.context, cheroot, ansible-cmdb, portend, jaraco.text, jaraco.collections, cherrypy, hostlist\n",
            "Successfully installed ansible-cmdb-1.31 autocommand-2.2.2 backports.tarfile-1.2.0 cheroot-10.0.1 cherrypy-18.10.0 hostlist-1.4.8 jaraco.collections-5.1.0 jaraco.context-6.0.1 jaraco.functools-4.1.0 jaraco.text-4.0.0 jsonxs-0.6 mako-1.3.8 portend-3.2.0 tempora-5.7.0 typing-3.7.4.3 ushlex-0.99.1 zc.lockfile-3.0.post1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "b7c4e314f35d4776a7fe3266ba37804d",
              "pip_warning": {
                "packages": [
                  "backports",
                  "jaraco",
                  "typing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Collecting mmcv==1.3.8\n",
            "  Downloading mmcv-1.3.8.tar.gz (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv==1.3.8)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==1.3.8) (6.0.2)\n",
            "Collecting yapf (from mmcv==1.3.8)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.3.8) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==1.3.8) (2.2.1)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.3.8-py2.py3-none-any.whl size=451082 sha256=afb41e76589fb45b06f26a1c142b8f04dba3624a84848f31f40761fc70de16f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/6d/b8/f51fdd13994b141f943a88961c4a315f0b614b20ab1ba2e2c7\n",
            "Successfully built mmcv\n",
            "Installing collected packages: addict, yapf, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-1.3.8 yapf-0.43.0\n",
            "Collecting mmsegmentation==0.14.1\n",
            "  Downloading mmsegmentation-0.14.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (1.26.4)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==0.14.1) (3.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==0.14.1) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmsegmentation==0.14.1) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==0.14.1) (1.17.0)\n",
            "Downloading mmsegmentation-0.14.1-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mmsegmentation\n",
            "Successfully installed mmsegmentation-0.14.1\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Collecting easydict==1.9\n",
            "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: easydict\n",
            "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6360 sha256=1182a62f9c107252925d615f5b381ef9089ba9a8d00f630fbdfbc663bff03316\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/d2/35/4c11d19a72280492846f4c4df975311a2bac475e8021f86c1d\n",
            "Successfully built easydict\n",
            "Installing collected packages: easydict\n",
            "  Attempting uninstall: easydict\n",
            "    Found existing installation: easydict 1.13\n",
            "    Uninstalling easydict-1.13:\n",
            "      Successfully uninstalled easydict-1.13\n",
            "Successfully installed easydict-1.9\n",
            "Collecting pyyaml==5.3\n",
            "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Collecting torch>=2.0.0 (from torchmetrics)\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (58.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lightning-utilities-0.11.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 torchmetrics-1.6.1 triton-3.1.0\n",
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.14.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.27.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
            "Collecting torch>=1.9.0 (from open_clip_torch)\n",
            "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (11.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch) (58.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "Installing collected packages: ftfy, torch, open_clip_torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.10.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ftfy-6.3.1 open_clip_torch-2.29.0 torch-1.13.1\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Collecting python-hostlist\n",
            "  Downloading python-hostlist-2.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python-hostlist\n",
            "  Building wheel for python-hostlist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-hostlist: filename=python_hostlist-2.2.1-py3-none-any.whl size=39617 sha256=d98c6bb65aee6ae590b89e57c45d96afd1c95db63845c817ae29066edd28c14d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/a0/4e/057d4c6df390bb2f8c7c171df7bb39c124549a6b66cbe3480f\n",
            "Successfully built python-hostlist\n",
            "Installing collected packages: python-hostlist\n",
            "Successfully installed python-hostlist-2.2.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# Load the YAML file\n",
        "with open('/content/CAST/environment.yaml', 'r') as file:\n",
        "    env_data = yaml.safe_load(file)\n",
        "\n",
        "# Extract dependencies\n",
        "dependencies = env_data.get('dependencies', [])\n",
        "\n",
        "# Install pip dependencies\n",
        "for dep in dependencies:\n",
        "    if isinstance(dep, str):  # If it's a pip package\n",
        "        !pip install {dep}\n",
        "    elif isinstance(dep, dict) and 'pip' in dep:  # If it's a pip section\n",
        "        for pip_dep in dep['pip']:\n",
        "            !pip install {pip_dep}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJKr_Wy9cxAj",
        "outputId": "861a05dd-c141-45ec-9bc7-bb9ca62bdf34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cast_models  docs\t       figs\tmisc\t notebooks  scripts    setup.py  vits_vis_utils\n",
            "deit\t     environment.yaml  LICENSE\tmoco-v3  README.md  segmenter  SPML\n"
          ]
        }
      ],
      "source": [
        "!ls /content/CAST  # Check if cast.py is present\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/CAST/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRYING CAST WITH SLIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from typing import Optional, Callable, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.datasets.folder as folder\n",
        "from skimage.segmentation import slic\n",
        "\n",
        "import moco.loader\n",
        "\n",
        "\n",
        "class ImageFolder(datasets.ImageFolder):\n",
        "    def __init__(self,\n",
        "                 root: str,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 target_transform: Optional[Callable] = None,\n",
        "                 normalize: Optional[Callable] = None,\n",
        "                 loader: Callable[[str], Any] = folder.default_loader,\n",
        "                 is_valid_file: Optional[Callable[[str], bool]] = None,\n",
        "                 n_segments: int = 256,\n",
        "                 compactness: float = 10.0,\n",
        "                 blur_ops: Optional[Callable] = None,\n",
        "                 slic_scale_factor=1.0):\n",
        "        super(ImageFolder, self).__init__(\n",
        "            root=root,\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            loader=loader,\n",
        "            is_valid_file=is_valid_file)\n",
        "        self.normalize = normalize\n",
        "        self.n_segments = n_segments\n",
        "        self.compactness = compactness\n",
        "        self.blur_ops = blur_ops\n",
        "        self.slic_scale_factor = slic_scale_factor\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any, Any]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (sample, target) where target is class_index of the target class.\n",
        "        \"\"\"\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        # Prepare arguments when multi-view pipeline is adopted\n",
        "        compactness = self.compactness\n",
        "        blur_ops = self.blur_ops\n",
        "        n_segments = self.n_segments\n",
        "        slic_scale_factor = self.slic_scale_factor\n",
        "        if isinstance(sample, (list, tuple)):\n",
        "            if not isinstance(compactness, (list, tuple)):\n",
        "                compactness = [compactness] * len(sample)\n",
        "\n",
        "            if not isinstance(n_segments, (list, tuple)):\n",
        "                n_segments = [n_segments] * len(sample)\n",
        "\n",
        "            if not isinstance(blur_ops, (list, tuple)):\n",
        "                blur_ops = [blur_ops] * len(sample)\n",
        "\n",
        "            if not isinstance(slic_scale_factor, (list, tuple)):\n",
        "                slic_scale_factor = [slic_scale_factor] * len(sample)\n",
        "\n",
        "\n",
        "        # Generate superpixels\n",
        "        if isinstance(sample, (list, tuple)):\n",
        "            segments = []\n",
        "            for samp, comp, n_seg, blur_op, scale in zip(sample, compactness, n_segments, blur_ops, slic_scale_factor):\n",
        "                if blur_op is not None:\n",
        "                    samp = blur_op(samp)\n",
        "                samp = F.interpolate(samp.unsqueeze(0),\n",
        "                                     scale_factor=scale,\n",
        "                                     mode='bilinear').squeeze(0)\n",
        "                _comp = comp\n",
        "                while True:\n",
        "                  segment = slic(samp.data.numpy().transpose(1, 2, 0),\n",
        "                                 n_segments=n_seg,\n",
        "                                 compactness=_comp,\n",
        "                                 convert2lab=True,\n",
        "                                 start_label=0)\n",
        "                  if np.unique(segment).size < n_seg // 2:\n",
        "                      _comp *= 3\n",
        "                  else:\n",
        "                      break\n",
        "                segment = torch.LongTensor(segment)\n",
        "                segments.append(segment)\n",
        "        else:\n",
        "            if blur_ops is not None:\n",
        "                samp = blur_ops(sample)\n",
        "            samp = F.interpolate(samp.unsqueeze(0),\n",
        "                                 scale_factor=slic_scale_factor,\n",
        "                                 mode='bilinear').squeeze(0)\n",
        "            _comp = compactness\n",
        "            while True:\n",
        "              segments = slic(samp.data.numpy().transpose(1, 2, 0),\n",
        "                              n_segments=n_segments,\n",
        "                              compactness=_comp,\n",
        "                              convert2lab=True,\n",
        "                              start_label=0)\n",
        "              if np.unique(segments).size < n_segments // 2:\n",
        "                  _comp *= 3\n",
        "              else:\n",
        "                  break\n",
        "            segments = torch.LongTensor(segments)\n",
        "\n",
        "        # Normalize the images\n",
        "        if self.normalize is not None:\n",
        "          if isinstance(sample, (list, tuple)):\n",
        "              sample = [self.normalize(samp) for samp in sample]\n",
        "          else:\n",
        "              sample = self.normalize(sample)\n",
        "\n",
        "        return sample, segments, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfInpBqczfX",
        "outputId": "d3e3e5f3-7265-4cf0-dd39-c1af200d82d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-28 13:04:46--  https://huggingface.co/twke/CAST/resolve/main/snapshots/moco/imagenet1k/cast_base/checkpoint_0099.pth.tar\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.97, 13.35.202.34, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/07/97/07974173035d95e4743a789a61e1809d83f2e970a7a22886429996b77098f621/b254b05c9658b8cdc99bf87aeb9e77cb45bfe9d5035b7395a5274b89e73dd151?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint_0099.pth.tar%3B+filename%3D%22checkpoint_0099.pth.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1735650286&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTY1MDI4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzA3Lzk3LzA3OTc0MTczMDM1ZDk1ZTQ3NDNhNzg5YTYxZTE4MDlkODNmMmU5NzBhN2EyMjg4NjQyOTk5NmI3NzA5OGY2MjEvYjI1NGIwNWM5NjU4YjhjZGM5OWJmODdhZWI5ZTc3Y2I0NWJmZTlkNTAzNWI3Mzk1YTUyNzRiODllNzNkZDE1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=LWvnCi95-cHMivFo0ssKexUFXVjxg3punXihsrNTTUtWdrMvkUdvy5V2IxiafIpzKw64Ipjoo0rPZYKjNJ0Knlu%7EHk-uh0GB2UYGNKwMseFQpdVTE3HSyh8EN6IKojs3ZBZzoMa0niJzE21HROipcKH3BcFWXsL2vIsCwQa56LzkYNftmIp%7EidTQ72YVXM9H%7EtMBz6SRmZb-IfIP1xnryQGDhyH8x72ahAMKteBWt1Zez6hTZVgpuy-TiQu6cvHGn3JU8eKC4Lr6ZFuaJRenFhhHP8%7Eomf2WccgGmH8p5kRzo%7ER5P2Jom2ntTIdxvwe6EeVq0qqouefH9Nnf91s4pA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-12-28 13:04:47--  https://cdn-lfs-us-1.hf.co/repos/07/97/07974173035d95e4743a789a61e1809d83f2e970a7a22886429996b77098f621/b254b05c9658b8cdc99bf87aeb9e77cb45bfe9d5035b7395a5274b89e73dd151?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint_0099.pth.tar%3B+filename%3D%22checkpoint_0099.pth.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1735650286&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNTY1MDI4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzA3Lzk3LzA3OTc0MTczMDM1ZDk1ZTQ3NDNhNzg5YTYxZTE4MDlkODNmMmU5NzBhN2EyMjg4NjQyOTk5NmI3NzA5OGY2MjEvYjI1NGIwNWM5NjU4YjhjZGM5OWJmODdhZWI5ZTc3Y2I0NWJmZTlkNTAzNWI3Mzk1YTUyNzRiODllNzNkZDE1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=LWvnCi95-cHMivFo0ssKexUFXVjxg3punXihsrNTTUtWdrMvkUdvy5V2IxiafIpzKw64Ipjoo0rPZYKjNJ0Knlu%7EHk-uh0GB2UYGNKwMseFQpdVTE3HSyh8EN6IKojs3ZBZzoMa0niJzE21HROipcKH3BcFWXsL2vIsCwQa56LzkYNftmIp%7EidTQ72YVXM9H%7EtMBz6SRmZb-IfIP1xnryQGDhyH8x72ahAMKteBWt1Zez6hTZVgpuy-TiQu6cvHGn3JU8eKC4Lr6ZFuaJRenFhhHP8%7Eomf2WccgGmH8p5kRzo%7ER5P2Jom2ntTIdxvwe6EeVq0qqouefH9Nnf91s4pA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.155.68.50, 18.155.68.69, 18.155.68.103, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.155.68.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2076601354 (1.9G) [application/x-tar]\n",
            "Saving to: ‘cast_base_checkpoint.pth.tar’\n",
            "\n",
            "cast_base_checkpoin 100%[===================>]   1.93G  42.1MB/s    in 51s     \n",
            "\n",
            "2024-12-28 13:05:38 (38.8 MB/s) - ‘cast_base_checkpoint.pth.tar’ saved [2076601354/2076601354]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O  cast_base_checkpoint.pth.tar https://huggingface.co/twke/CAST/resolve/main/snapshots/moco/imagenet1k/cast_base/checkpoint_0099.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fESVsYYVc7wL",
        "outputId": "a1196735-cc97-4b47-e39b-e14520b7e001"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "from cast_models.cast import cast_base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8hDkYDdc9bB",
        "outputId": "d20679f5-7887-4e91-953c-cf4bf0951a17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "from functools import partial\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import skimage.color as sk_color\n",
        "import skimage.morphology as sk_morph\n",
        "import scipy.io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import ImageFolder\n",
        "\n",
        "sys.path.append('/content/CAST/')\n",
        "import cast_models.cast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CRofa1i_fWE3"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/content/CAST/notebooks/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G6pmp6t4dAVf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from open_clip import create_model_and_transforms, get_tokenizer\n",
        "\n",
        "import numpy as np\n",
        "from torchmetrics import JaccardIndex\n",
        "\n",
        "from dataset import PartImageNetWithMask, PredictedMask\n",
        "from utils import TextFeatures, get_masked_pred_c, get_masked_pred_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEdJ8AUwdCC2",
        "outputId": "b8b916cb-a61b-419f-9ddc-5f925a17dded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n"
          ]
        }
      ],
      "source": [
        "MODEL_CLASS_NAME = 'cast_base'\n",
        "CHECKPOINT_PATH = '/content/cast_base_checkpoint.pth.tar'\n",
        "\n",
        "model = cast_models.cast.__dict__[MODEL_CLASS_NAME]().cuda()\n",
        "ckpt = torch.load(CHECKPOINT_PATH, map_location='cuda:0')\n",
        "state_dict = {k[len('module.base_encoder.'):]: v for k, v in ckpt['state_dict'].items()\n",
        "              if 'module.base_encoder.' in k and 'head' not in k}\n",
        "msg = model.load_state_dict(state_dict, strict=False)\n",
        "print(msg)\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Move model to CPU (if it's not already)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Zw6GBbNsdDlW"
      },
      "outputs": [],
      "source": [
        "sys.path.append('/content/CAST/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVpwpF0gdGHR",
        "outputId": "80b93355-a32c-41a9-ccc2-ce54887d55b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset restructured successfully at /content/CAST/data/PartimageNet\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "zip_file_path = \"/content/val.zip\"  # Path to your uploaded zip file\n",
        "extract_folder = \"/content/extracted_val_dataset2\"\n",
        "structured_folder = \"/content/CAST/data/PartimageNet\"  # Target folder to restructure dataset\n",
        "annotation_file_path= '/content/val.json'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "\n",
        "macosx_folder = os.path.join(extract_folder, \"__MACOSX\")\n",
        "if os.path.exists(macosx_folder):\n",
        "    shutil.rmtree(macosx_folder)\n",
        "\n",
        "\n",
        "test_folder = os.path.join(extract_folder, \"val\")\n",
        "\n",
        "annotations_folder = os.path.join(structured_folder, \"annotations\")\n",
        "images_folder = os.path.join(structured_folder, \"images/val\")\n",
        "\n",
        "os.makedirs(annotations_folder, exist_ok=True)\n",
        "os.makedirs(images_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "for class_folder in os.listdir(test_folder):\n",
        "    source_path = os.path.join(test_folder, class_folder)\n",
        "    target_path = os.path.join(images_folder, class_folder)\n",
        "    if os.path.isdir(source_path):\n",
        "        shutil.move(source_path, target_path)\n",
        "\n",
        "\n",
        "shutil.copy(annotation_file_path, os.path.join(annotations_folder, \"val.json\"))\n",
        "\n",
        "print(f\"Dataset restructured successfully at {structured_folder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "\n",
        "def gaussian_blur(image, ksize=(5, 5), sigma=1.0):\n",
        "    \"\"\"\n",
        "    Apply Gaussian blur to an image.\n",
        "\n",
        "    Args:\n",
        "        image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
        "        ksize (tuple): Kernel size for the Gaussian blur.\n",
        "        sigma (float): Standard deviation for Gaussian kernel.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Blurred image tensor of shape (C, H, W).\n",
        "    \"\"\"\n",
        "    \n",
        "    img_np = image.permute(1, 2, 0).numpy()\n",
        "    img_np = cv2.GaussianBlur(img_np, ksize, sigma)\n",
        "\n",
        "  \n",
        "    return torch.from_numpy(img_np).permute(2, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wI5-sEwvdUh9"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = '/content/CAST/data/PartimageNet/images/val/'\n",
        "\n",
        "SAVE_ROOT = '../pred_segs/'\n",
        "\n",
        "class ReturnIndexDataset(datasets.ImageFolder):\n",
        "    def __getitem__(self, idx):\n",
        "        img, seg, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n",
        "        return img, seg, lab, idx\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225])\n",
        "\n",
        "augmentation = [\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = ReturnIndexDataset(\n",
        "    DATA_ROOT,\n",
        "    transforms.Compose(augmentation),\n",
        "    normalize=normalize,\n",
        "    n_segments=196,\n",
        "    compactness=10.0,\n",
        "    blur_ops=lambda x: gaussian_blur(x, ksize=(3, 3), sigma=1.5),\n",
        "    slic_scale_factor=1.0)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CT9Ny1yBdbKW"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i, (img, suppixel, label, img_inds) in enumerate(train_loader):\n",
        "    img = img.cpu() # input images\n",
        "    suppixel = suppixel.cpu() # superpixels\n",
        "\n",
        "    # Forward pass to return intermediate groupings\n",
        "    intermediates = model.forward_features(img, suppixel)\n",
        "\n",
        "    # Aggregate groupings from fine to coarse levels\n",
        "    segmentations = {}\n",
        "    prev_labels = {}\n",
        "    # Iterate through the finest to the coarsest scales\n",
        "    for level in [1, 2, 3, 4]:\n",
        "        # Iterate through the mini-batch\n",
        "        for b in range(img.shape[0]):\n",
        "            # Grouping logit for the current level\n",
        "            logit = intermediates['logit{:d}'.format(level)][b]\n",
        "            label = torch.argmax(logit, dim=-1).detach()\n",
        "            if level == 1 and len(label) < 196:\n",
        "                npad = torch.unique(suppixel).shape[0] - logit.shape[0]\n",
        "                label = torch.concat([label, torch.tensor([label[-1]] * npad, device=label.device)])\n",
        "\n",
        "            # Gather coarser grouping at the current level\n",
        "            # The level-1 grouping index for each level-0 group is [1, 2, 2, 0, 1, 1, 0]\n",
        "            # The level-2 grouping index for each level-1 group is [0, 1, 0]\n",
        "            # We infer the level-2 grouping for each level-0 group as [1, 0, 0, 0, 1, 1, 0]\n",
        "            if level > 1:\n",
        "                prev_label = prev_labels['level{:d}'.format(level-1)][b]\n",
        "                label = torch.gather(label, 0, prev_label.view(-1).long())\n",
        "\n",
        "            if prev_labels.get('level{:d}'.format(level), None) is None:\n",
        "                prev_labels['level{:d}'.format(level)] = []\n",
        "            prev_labels['level{:d}'.format(level)].append(label)\n",
        "\n",
        "            # Gather groupings for each superpixel\n",
        "            label = torch.gather(label, 0, suppixel[b].view(-1))\n",
        "            label = label.view(suppixel.shape[-2:])\n",
        "\n",
        "            # Save segmentations by levels\n",
        "            save_root = os.path.join(SAVE_ROOT, MODEL_CLASS_NAME, 'level{:d}'.format(level))\n",
        "            os.makedirs(save_root, exist_ok=True)\n",
        "\n",
        "            file_name = train_dataset.samples[img_inds[b]][0]\n",
        "            file_name = file_name.split('/')[-1].split('.')[0]\n",
        "            with open(os.path.join(save_root, '{}.npy'.format(file_name)), 'wb') as f:\n",
        "                np.save(f, label.cpu().data.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "a5f5a74a05474b81b1b8075698d6f188",
            "32df618b5eac4abe8ad6cf884c698267",
            "e02599343dd34bd5a758a6fddd07a917",
            "2e93f15c904f4c3ca845dd0795a98501",
            "4b94d3a190f3455daec4b6bc0b5ef4c2",
            "d5d06834d7094a8ca147877dc1ae6984",
            "08a8315b9b7746ad8fd5102c21a55e9d",
            "e431dd1b81a144b09bda557ad0f6ed24",
            "99899318e560455f9f30b63218b53425",
            "88491f27a0c64b6d9586b936536a69c7",
            "8fdfb5cbb8f5417caf129b3c3888f9a2"
          ]
        },
        "id": "3QSwe46ddbHA",
        "outputId": "111a1eb9-0637-4a89-ae32-0ef6f9f1d93e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5f5a74a05474b81b1b8075698d6f188",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/open_clip/factory.py:372: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\"\n",
        "torch.cuda.set_device(device)\n",
        "\n",
        "clip, _, clip_transform = create_model_and_transforms('ViT-B-16', pretrained='openai')\n",
        "tokenizer = get_tokenizer('ViT-B-16')\n",
        "\n",
        "clip = clip.to(device)\n",
        "\n",
        "normalize = clip_transform.transforms[-1]\n",
        "img_transform = T.Compose([\n",
        "    T.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop([224, 224]),\n",
        "])\n",
        "seg_transform = T.Compose([\n",
        "    T.Resize(224, interpolation=InterpolationMode.NEAREST),\n",
        "    T.CenterCrop([224, 224]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lekKPvBfp65",
        "outputId": "1183084c-3ac9-4f4f-9694-4aeaab8681e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.39s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = '/content/CAST/data/PartimageNet/'\n",
        "SAVE_ROOT = '../pred_segs/'\n",
        "\n",
        "model_name = \"cast_base\"\n",
        "\n",
        "\n",
        "img_root = os.path.join(DATA_ROOT, 'images/val')\n",
        "ano_root = os.path.join(DATA_ROOT, 'annotations/val.json')\n",
        "\n",
        "pred_c_root = os.path.join(SAVE_ROOT, model_name, 'level4')\n",
        "pred_f_root = os.path.join(SAVE_ROOT, model_name, 'level3')\n",
        "\n",
        "# Output: image, seg_c, seg_f\n",
        "dataset = PartImageNetWithMask(img_root, ano_root, clip_transform, seg_transform)\n",
        "\n",
        "# Predicted segments by CAST or ViT\n",
        "mask_dataset_c = PredictedMask(pred_c_root, ano_root)\n",
        "mask_dataset_f = PredictedMask(pred_f_root, ano_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxYrO8ANfs5V",
        "outputId": "e32cd81c-e39c-4533-b466-fd4430254242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Quadruped', 'Biped', 'Fish', 'Bird', 'Snake', 'Reptile', 'Car', 'Bicycle', 'Boat', 'Aeroplane', 'Bottle']\n",
            "['Quadruped Head', 'Quadruped Body', 'Quadruped Foot', 'Quadruped Tail', 'Biped Head', 'Biped Body', 'Biped Hand', 'Biped Foot', 'Biped Tail', 'Fish Head', 'Fish Body', 'Fish Fin', 'Fish Tail', 'Bird Head', 'Bird Body', 'Bird Wing', 'Bird Foot', 'Bird Tail', 'Snake Head', 'Snake Body', 'Reptile Head', 'Reptile Body', 'Reptile Foot', 'Reptile Tail', 'Car Body', 'Car Tier', 'Car Side Mirror', 'Bicycle Body', 'Bicycle Head', 'Bicycle Seat', 'Bicycle Tier', 'Boat Body', 'Boat Sail', 'Aeroplane Head', 'Aeroplane Body', 'Aeroplane Engine', 'Aeroplane Wing', 'Aeroplane Tail', 'Bottle Mouth', 'Bottle Body']\n"
          ]
        }
      ],
      "source": [
        "print(dataset.classname_c)\n",
        "print(dataset.classname_f)\n",
        "\n",
        "text_features = TextFeatures(clip, tokenizer,\n",
        "                             dataset.classname_c,\n",
        "                             dataset.classname_f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAGRnliRfs12",
        "outputId": "db3ac617-eca3-43bb-bea7-6d79a98057a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/2957    40.30/16.43\n",
            "200/2957    36.15/14.90\n",
            "300/2957    30.29/12.79\n",
            "400/2957    27.23/11.62\n",
            "500/2957    26.03/11.40\n",
            "600/2957    26.41/12.33\n",
            "700/2957    26.45/13.05\n",
            "800/2957    26.86/13.85\n",
            "900/2957    27.39/15.06\n",
            "1000/2957    27.10/14.76\n",
            "1100/2957    26.75/14.39\n",
            "1200/2957    26.56/14.17\n",
            "1300/2957    26.36/13.90\n",
            "1400/2957    26.63/13.87\n",
            "1500/2957    26.86/13.80\n",
            "1600/2957    27.09/13.79\n",
            "1700/2957    27.89/13.90\n",
            "1800/2957    28.61/13.97\n",
            "1900/2957    29.20/13.99\n",
            "2000/2957    29.89/14.10\n",
            "2100/2957    30.29/14.20\n",
            "2200/2957    30.56/14.24\n",
            "2300/2957    30.69/14.20\n",
            "2400/2957    30.96/14.21\n",
            "2500/2957    31.11/14.21\n",
            "2600/2957    31.32/14.19\n",
            "2700/2957    31.50/14.21\n",
            "2800/2957    31.64/14.25\n",
            "2900/2957    31.61/14.27\n",
            "2957/2957    31.52/14.29\n"
          ]
        }
      ],
      "source": [
        "def print_values():\n",
        "    if accs_c and accs_f:  # Check if there are values to compute the mean\n",
        "        print(\"{:d}/{:d}    {:.2f}/{:.2f}\".format(\n",
        "            index + 1, len(dataset),\n",
        "            np.mean(accs_c) * 100, np.mean(accs_f) * 100,\n",
        "        ))\n",
        "\n",
        "jaccard_c = JaccardIndex(task=\"multiclass\", num_classes=11+1)\n",
        "jaccard_f = JaccardIndex(task=\"multiclass\", num_classes=40+1)\n",
        "\n",
        "accs_c, accs_f = [], []\n",
        "for index in range(len(dataset)):\n",
        "    try:\n",
        "        img, seg_c, seg_f = dataset[index]\n",
        "\n",
        "        mask_c = mask_dataset_c[index]\n",
        "        mask_f = mask_dataset_f[index]\n",
        "\n",
        "        pred_c = get_masked_pred_c(clip, text_features, img, mask_c)\n",
        "        pred_f = get_masked_pred_f(clip, text_features, img, mask_f, pred_c)\n",
        "\n",
        "        # Ensure predictions are valid before calculating Jaccard index\n",
        "        if pred_c is not None and pred_f is not None:\n",
        "            accs_c.append(jaccard_c(pred_c, seg_c).item())\n",
        "            accs_f.append(jaccard_f(pred_f, seg_f).item())\n",
        "        else:\n",
        "            print(f\"Skipping index {index}: Invalid prediction\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error at index {index}: {e}\")\n",
        "\n",
        "    if (index + 1) % 100 == 0:\n",
        "        print_values()\n",
        "\n",
        "index = len(dataset) - 1\n",
        "print_values()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08a8315b9b7746ad8fd5102c21a55e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e93f15c904f4c3ca845dd0795a98501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88491f27a0c64b6d9586b936536a69c7",
            "placeholder": "​",
            "style": "IPY_MODEL_8fdfb5cbb8f5417caf129b3c3888f9a2",
            "value": " 599M/599M [00:03&lt;00:00, 168MB/s]"
          }
        },
        "32df618b5eac4abe8ad6cf884c698267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d06834d7094a8ca147877dc1ae6984",
            "placeholder": "​",
            "style": "IPY_MODEL_08a8315b9b7746ad8fd5102c21a55e9d",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "4b94d3a190f3455daec4b6bc0b5ef4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88491f27a0c64b6d9586b936536a69c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fdfb5cbb8f5417caf129b3c3888f9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99899318e560455f9f30b63218b53425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5f5a74a05474b81b1b8075698d6f188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32df618b5eac4abe8ad6cf884c698267",
              "IPY_MODEL_e02599343dd34bd5a758a6fddd07a917",
              "IPY_MODEL_2e93f15c904f4c3ca845dd0795a98501"
            ],
            "layout": "IPY_MODEL_4b94d3a190f3455daec4b6bc0b5ef4c2"
          }
        },
        "d5d06834d7094a8ca147877dc1ae6984": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02599343dd34bd5a758a6fddd07a917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e431dd1b81a144b09bda557ad0f6ed24",
            "max": 598516980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99899318e560455f9f30b63218b53425",
            "value": 598516980
          }
        },
        "e431dd1b81a144b09bda557ad0f6ed24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
